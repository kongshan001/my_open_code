# token.ts - Token è®¡ç®—å’Œä¸Šä¸‹æ–‡ç®¡ç†

## æ¦‚è¿°

ä¼°ç®— Token æ•°é‡ï¼Œè®¡ç®—ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡ï¼Œæä¾›è­¦å‘Šæœºåˆ¶ã€‚

## æ ¸å¿ƒæ¦‚å¿µ

### Token æ˜¯ä»€ä¹ˆï¼Ÿ

Token æ˜¯ LLM å¤„ç†æ–‡æœ¬çš„åŸºæœ¬å•ä½ï¼š
- è‹±æ–‡å•è¯ï¼šçº¦ 0.75 ä¸ª token/å•è¯
- ä¸­æ–‡å­—ç¬¦ï¼šçº¦ 0.5 ä¸ª token/å­—ç¬¦
- ç®€åŒ–ä¼°ç®—ï¼š4 å­—ç¬¦ â‰ˆ 1 token

### ä¸Šä¸‹æ–‡é™åˆ¶

æ¯ä¸ªæ¨¡å‹éƒ½æœ‰æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼š

| æ¨¡å‹ | ä¸Šä¸‹æ–‡é•¿åº¦ | è¾“å‡ºé™åˆ¶ |
|------|-----------|---------|
| GLM-4.7 | 128K | 4K |
| Claude 3.5 | 200K | 8K |
| GPT-4 | 8K/32K | 4K/8K |

## API è¯¦è§£

### å¸¸é‡

#### CHARS_PER_TOKEN

å­—ç¬¦åˆ° token çš„è½¬æ¢æ¯”ä¾‹ï¼š

```typescript
const CHARS_PER_TOKEN = 4;  // 4å­—ç¬¦ â‰ˆ 1 token
```

### å‡½æ•°

#### estimateTokens(text: string): number

ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡ã€‚

**ç®—æ³•ï¼š**
```typescript
Math.round(text.length / CHARS_PER_TOKEN)
```

**ç¤ºä¾‹ï¼š**

```typescript
estimateTokens("Hello World");  // 3 (11 chars / 4)
estimateTokens("ä½ å¥½ä¸–ç•Œ");      // 2 (4 chars / 4)
```

**æ³¨æ„ï¼š**
- è¿™æ˜¯ç®€åŒ–ä¼°ç®—ï¼Œå®é™…æ•°é‡å¯èƒ½ä¸åŒ
- çœŸå® token è®¡ç®—éœ€è¦ä½¿ç”¨ tiktoken

#### calculateMessageTokens(content: string): number

`estimateTokens` çš„åˆ«åï¼Œè¯­ä¹‰æ›´æ¸…æ™°ã€‚

#### getModelLimits(modelName: string): ModelLimits

è·å–æ¨¡å‹çš„ä¸Šä¸‹æ–‡é™åˆ¶ã€‚

**æ”¯æŒçš„æ¨¡å‹ï¼š**

```typescript
const MODEL_LIMITS = {
  'glm-4.7': {
    context: 128000,   // 128K ä¸Šä¸‹æ–‡
    output: 4096,      // 4K è¾“å‡º
  },
  'default': {
    context: 8192,
    output: 4096,
  }
};
```

**åŒ¹é…é€»è¾‘ï¼š**

```typescript
// æ¨¡ç³ŠåŒ¹é…æ¨¡å‹åç§°
if (modelName.toLowerCase().includes('glm-4.7')) {
  return MODEL_LIMITS['glm-4.7'];
}
```

#### calculateContextUsage(messages, modelName): ContextUsage

è®¡ç®—å½“å‰ä¸Šä¸‹æ–‡ä½¿ç”¨æƒ…å†µã€‚

**å‚æ•°ï¼š**
- `messages`: æ¶ˆæ¯æ•°ç»„
- `modelName`: æ¨¡å‹åç§°

**è¿”å›å€¼ï¼š**

```typescript
{
  totalTokens: number,        // æ€»ä½¿ç”¨ token æ•°
  contextLimit: number,       // ä¸Šä¸‹æ–‡é™åˆ¶
  usagePercentage: number,    // ä½¿ç”¨ç‡ï¼ˆ0-100+ï¼‰
  remainingTokens: number,    // å‰©ä½™ token æ•°
  isNearLimit: boolean,       // â‰¥80%
  isOverflow: boolean,        // >100%
  inputTokens: number,        // è¾“å…¥ token æ•°
  outputTokens: number        // è¾“å‡º token æ•°
}
```

**è®¡ç®—é€»è¾‘ï¼š**

```typescript
// ç»Ÿè®¡è¾“å…¥å’Œè¾“å‡º
totalTokens = inputTokens + outputTokens;

// è®¡ç®—ç™¾åˆ†æ¯”
usagePercentage = Math.round((totalTokens / limit) * 100);

// æ£€æŸ¥è­¦å‘Šæ¡ä»¶
isNearLimit = usagePercentage >= 80;
isOverflow = totalTokens > contextLimit;
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```typescript
const messages = [
  { role: 'user', content: 'Hello' },
  { role: 'assistant', content: 'Hi there!' }
];

const usage = calculateContextUsage(messages, 'glm-4.7');
console.log(usage);
// {
//   totalTokens: 5,
//   contextLimit: 128000,
//   usagePercentage: 0,
//   remainingTokens: 127995,
//   isNearLimit: false,
//   isOverflow: false,
//   inputTokens: 2,
//   outputTokens: 3
// }
```

#### formatContextUsage(usage: ContextUsage): string

æ ¼å¼åŒ–æ˜¾ç¤ºä½¿ç”¨ç‡ã€‚

**é¢œè‰²ç¼–ç ï¼š**

| ä½¿ç”¨ç‡ | å›¾æ ‡ | çŠ¶æ€ |
|--------|------|------|
| <50% | ğŸŸ¢ | æ­£å¸¸ |
| 50-79% | ğŸŸ  | æ³¨æ„ |
| 80-89% | ğŸŸ¡ | è­¦å‘Š |
| â‰¥90% | ğŸ”´ | ä¸¥é‡ |

**è¾“å‡ºæ ¼å¼ï¼š**

```typescript
// æ­£å¸¸çŠ¶æ€
ğŸŸ¢ Context: 5% (3,200/128,000) | Remaining: 124,800

// è­¦å‘ŠçŠ¶æ€
ğŸŸ¡ Context: 82% (105,000/128,000) | Remaining: 23,000 [âš ï¸ Near Limit]

// æº¢å‡ºçŠ¶æ€
ğŸ”´ Context: 105% (134,400/128,000) | Remaining: -6,400 [âš ï¸ OVERFLOW]
```

#### getContextWarning(usage: ContextUsage): string | null

è·å–è­¦å‘Šæ¶ˆæ¯ã€‚

**è­¦å‘Šçº§åˆ«ï¼š**

```typescript
if (isOverflow) {
  return "âš ï¸ Context overflow! ...";
}
if (usagePercentage >= 90) {
  return "âš ï¸ Critical: Context usage at 90%. ...";
}
if (usagePercentage >= 80) {
  return "âš¡ Warning: Context usage at 80%. ...";
}
return null;
```

## ä½¿ç”¨åœºæ™¯

### 1. åŠ è½½ä¼šè¯æ—¶æ˜¾ç¤º

```typescript
const usage = calculateContextUsage(session.messages, config.model);
console.log(formatContextUsage(usage));
```

### 2. æ¯æ¬¡å¯¹è¯åæ›´æ–°

```typescript
await sessionManager.processMessage();
console.log(`\n${sessionManager.formatContextStatus()}\n`);
```

### 3. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©

```typescript
const warning = sessionManager.checkContextWarning();
if (warning) {
  console.log(warning);
  // æç¤ºç”¨æˆ·åˆ›å»ºæ–°ä¼šè¯
}
```

## æœ€ä½³å®è·µ

### 1. å®šæœŸæ˜¾ç¤ºä½¿ç”¨ç‡

åœ¨æ¯æ¬¡å¯¹è¯åæ˜¾ç¤ºï¼Œè®©ç”¨æˆ·äº†è§£å‰©ä½™ç©ºé—´ã€‚

### 2. æå‰è­¦å‘Š

åœ¨è¾¾åˆ° 80% æ—¶è­¦å‘Šï¼Œç»™ç”¨æˆ·é¢„ç•™æ“ä½œæ—¶é—´ã€‚

### 3. ä¼°ç®—å‡†ç¡®æ€§

å¦‚æœåˆ‡æ¢åˆ°çœŸå®æ¨¡å‹ï¼Œè€ƒè™‘ä½¿ç”¨ tiktokenï¼š

```typescript
// ä½¿ç”¨ tiktoken è¿›è¡Œç²¾ç¡®è®¡ç®—
import { encoding_for_model } from 'tiktoken';

const enc = encoding_for_model('gpt-4');
const tokens = enc.encode(text).length;
```

## æ‰©å±•

### æ·»åŠ æ–°æ¨¡å‹

```typescript
MODEL_LIMITS['claude-3.5'] = {
  context: 200000,
  output: 8192,
};
```

### è‡ªå®šä¹‰è­¦å‘Šé˜ˆå€¼

```typescript
const WARNING_THRESHOLD = 75;  // æ”¹ä¸º 75%
const CRITICAL_THRESHOLD = 85; // æ”¹ä¸º 85%
```
